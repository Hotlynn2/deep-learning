{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasets = MNIST(root = 'classification data/', download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = MNIST(root = 'classification data/', train = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "len(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = MNIST(root = 'classification data/', train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=L size=28x28 at 0x23BD0DFBC48>, 4)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "datasets[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=L size=28x28 at 0x23BD0DFD688>, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "test_data[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = MNIST(root = 'classification data/', train = True, transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "img, label = datasets[2]\n",
    "print(img.shape)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = MNIST(root = 'classification data/', train = False, transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "img, label = datasets[200]\n",
    "print(img.shape)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating training datasets and validation datasets\n",
    "def indices_selector(factor, data_num):\n",
    "    val_num_of_indices = int(factor * data_num)\n",
    "    total_indices = np.random.permutation(data_num)\n",
    "    return total_indices[val_num_of_indices:], total_indices[:val_num_of_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([34819, 47330,  5048, ..., 51918, 10369, 36881]),\n",
       " array([28554, 48301, 32924, ..., 46228,  3826, 41026]))"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "indices_selector(0.2, len(datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, val_indices = indices_selector(0.2, len(datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "train_data = DataLoader(datasets, batch_size, sampler = train_sampler)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "val_data = DataLoader(datasets, batch_size, sampler = val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_data:\n",
    "    print(x.shape)\n",
    "#     print(y)\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28*28\n",
    "ouput_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating model\n",
    "class MNIST_Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, ouput_classes)\n",
    "        \n",
    "    def forward(self, input_reshape):\n",
    "        input_reshape = input_reshape.reshape(-1, 28*28)\n",
    "        output = self.linear(input_reshape)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNIST_Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "20, 0.0928,  ..., 0.1016, 0.1147, 0.0841],\n",
      "        [0.1087, 0.1272, 0.1383,  ..., 0.0705, 0.1020, 0.1013],\n",
      "        ...,\n",
      "        [0.1083, 0.1008, 0.0881,  ..., 0.1050, 0.0870, 0.1139],\n",
      "        [0.1069, 0.1056, 0.0979,  ..., 0.0889, 0.1082, 0.0882],\n",
      "        [0.0791, 0.1131, 0.0802,  ..., 0.1296, 0.1039, 0.1176]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.1282, -0.0764,  0.0938,  0.5633, -0.1752,  0.1409, -0.1626,  0.0081,\n",
      "          0.3205,  0.0129],\n",
      "        [-0.0241,  0.1781, -0.0860,  0.1596, -0.1070, -0.0374, -0.0952, -0.0614,\n",
      "          0.0791,  0.1951]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.1019, 0.0830, 0.0984,  ..., 0.0904, 0.1235, 0.0908],\n",
      "        [0.0950, 0.1163, 0.0893,  ..., 0.0916, 0.1054, 0.1183],\n",
      "        [0.0913, 0.0922, 0.0954,  ..., 0.0908, 0.1152, 0.1119],\n",
      "        ...,\n",
      "        [0.1000, 0.0987, 0.1043,  ..., 0.1046, 0.1119, 0.1044],\n",
      "        [0.1076, 0.1074, 0.1127,  ..., 0.0990, 0.1076, 0.0822],\n",
      "        [0.0761, 0.1066, 0.1118,  ..., 0.0906, 0.1314, 0.1076]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.2576,  0.0005,  0.3079,  0.3071,  0.1217,  0.1488, -0.2763, -0.2293,\n",
      "          0.0061,  0.2097],\n",
      "        [ 0.2090,  0.1587, -0.1741,  0.3341, -0.2194, -0.0508, -0.1566,  0.1892,\n",
      "          0.0909, -0.0633]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.1166, 0.0902, 0.1226,  ..., 0.0716, 0.0907, 0.1111],\n",
      "        [0.1175, 0.1117, 0.0801,  ..., 0.1152, 0.1044, 0.0895],\n",
      "        [0.1189, 0.1160, 0.0945,  ..., 0.1169, 0.1104, 0.0923],\n",
      "        ...,\n",
      "        [0.0919, 0.1232, 0.1135,  ..., 0.0979, 0.1124, 0.1281],\n",
      "        [0.1129, 0.0911, 0.1207,  ..., 0.0998, 0.1158, 0.0764],\n",
      "        [0.0906, 0.0985, 0.0987,  ..., 0.0899, 0.1129, 0.1189]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[-0.0677, -0.1516, -0.0492,  0.1655, -0.0628,  0.1965, -0.0037,  0.1626,\n",
      "          0.0822,  0.0122],\n",
      "        [ 0.0391,  0.1650, -0.1844,  0.4091, -0.0254, -0.0522, -0.2806,  0.2141,\n",
      "          0.3046,  0.4304]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.0903, 0.0830, 0.0920,  ..., 0.1136, 0.1049, 0.0978],\n",
      "        [0.0915, 0.1037, 0.0731,  ..., 0.1090, 0.1193, 0.1353],\n",
      "        [0.1014, 0.1057, 0.1179,  ..., 0.0877, 0.0856, 0.0968],\n",
      "        ...,\n",
      "        [0.1094, 0.1065, 0.0819,  ..., 0.1016, 0.1110, 0.0982],\n",
      "        [0.1047, 0.1038, 0.0897,  ..., 0.1122, 0.1068, 0.1143],\n",
      "        [0.1131, 0.1056, 0.0870,  ..., 0.0806, 0.1177, 0.1002]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[-0.1686,  0.1593,  0.2427, -0.0435, -0.3439,  0.2866, -0.1195, -0.2855,\n",
      "          0.2367, -0.0225],\n",
      "        [-0.0538, -0.1114, -0.0794,  0.2718,  0.0031, -0.0617,  0.0641,  0.1311,\n",
      "          0.0704,  0.1356]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.0830, 0.1153, 0.1253,  ..., 0.0739, 0.1245, 0.0961],\n",
      "        [0.0907, 0.0856, 0.0884,  ..., 0.1091, 0.1027, 0.1096],\n",
      "        [0.0921, 0.0976, 0.0869,  ..., 0.1149, 0.0877, 0.1208],\n",
      "        ...,\n",
      "        [0.1050, 0.1229, 0.0881,  ..., 0.0825, 0.1267, 0.0867],\n",
      "        [0.1030, 0.0845, 0.0766,  ..., 0.0911, 0.1032, 0.1073],\n",
      "        [0.0869, 0.0879, 0.0942,  ..., 0.1352, 0.1141, 0.0884]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.0764,  0.3771, -0.0483,  0.3741, -0.1429, -0.1649,  0.0885,  0.3650,\n",
      "          0.2687,  0.0488],\n",
      "        [ 0.2564,  0.0810,  0.1868,  0.2813, -0.2016, -0.1049, -0.1699,  0.0958,\n",
      "         -0.0282, -0.0455]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.0934, 0.1262, 0.0825,  ..., 0.1247, 0.1133, 0.0909],\n",
      "        [0.1231, 0.1033, 0.1148,  ..., 0.1048, 0.0926, 0.0910],\n",
      "        [0.1117, 0.1085, 0.0716,  ..., 0.0802, 0.1294, 0.0945],\n",
      "        ...,\n",
      "        [0.0861, 0.1126, 0.1395,  ..., 0.0860, 0.1085, 0.0792],\n",
      "        [0.0995, 0.1164, 0.0907,  ..., 0.1087, 0.1082, 0.1112],\n",
      "        [0.1264, 0.1048, 0.0784,  ..., 0.0910, 0.1102, 0.0931]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.1564, -0.0982, -0.1664,  0.2940, -0.1946,  0.1189, -0.3531,  0.0042,\n",
      "          0.1705, -0.1082],\n",
      "        [-0.1829,  0.3455,  0.1819,  0.1243, -0.1860, -0.0317, -0.3529,  0.0988,\n",
      "          0.1792,  0.4161]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.1169, 0.0906, 0.0846,  ..., 0.1004, 0.1185, 0.0897],\n",
      "        [0.0764, 0.1297, 0.1101,  ..., 0.1013, 0.1098, 0.1391],\n",
      "        [0.0963, 0.1028, 0.1294,  ..., 0.0802, 0.1183, 0.0867],\n",
      "        ...,\n",
      "        [0.0946, 0.1118, 0.1033,  ..., 0.1018, 0.0964, 0.0962],\n",
      "        [0.0911, 0.1035, 0.1032,  ..., 0.1016, 0.1463, 0.0805],\n",
      "        [0.1051, 0.0819, 0.0813,  ..., 0.0921, 0.1047, 0.1071]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.0848,  0.0630,  0.1339,  0.2437,  0.2926,  0.1324, -0.0162, -0.0807,\n",
      "          0.0954,  0.1141],\n",
      "        [-0.0398, -0.0118,  0.2652,  0.0941, -0.0837,  0.1633, -0.2307, -0.0046,\n",
      "         -0.1191,  0.0316]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.0973, 0.0952, 0.1022,  ..., 0.0825, 0.0984, 0.1002],\n",
      "        [0.0946, 0.0973, 0.1283,  ..., 0.0980, 0.0874, 0.1016],\n",
      "        [0.1048, 0.1002, 0.1185,  ..., 0.1141, 0.1050, 0.1014],\n",
      "        ...,\n",
      "        [0.1059, 0.1078, 0.0966,  ..., 0.0935, 0.1194, 0.0838],\n",
      "        [0.1028, 0.1104, 0.0831,  ..., 0.1021, 0.1184, 0.1022],\n",
      "        [0.1163, 0.1074, 0.1009,  ..., 0.0765, 0.0910, 0.1234]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.3022,  0.2765,  0.1374,  0.1064, -0.1537,  0.0503,  0.0141,  0.1577,\n",
      "         -0.0404, -0.1920],\n",
      "        [-0.1526,  0.1807, -0.2518,  0.4524,  0.1600, -0.1534, -0.1184, -0.1429,\n",
      "          0.2945,  0.4315]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.1251, 0.1220, 0.1061,  ..., 0.1083, 0.0888, 0.0763],\n",
      "        [0.0775, 0.1082, 0.0702,  ..., 0.0783, 0.1212, 0.1390],\n",
      "        [0.1345, 0.1174, 0.1003,  ..., 0.0816, 0.1083, 0.0995],\n",
      "        ...,\n",
      "        [0.1066, 0.1042, 0.1333,  ..., 0.0893, 0.0970, 0.0887],\n",
      "        [0.0736, 0.1022, 0.0865,  ..., 0.1174, 0.1174, 0.1087],\n",
      "        [0.0999, 0.1183, 0.0870,  ..., 0.0792, 0.0876, 0.1175]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.1695,  0.3796, -0.1468, -0.2145,  0.1423, -0.2951, -0.1636, -0.1100,\n",
      "          0.0623,  0.1747],\n",
      "        [ 0.0402,  0.1369, -0.2189,  0.1328,  0.1192, -0.1708, -0.0610,  0.0702,\n",
      "          0.0110,  0.4218]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.1160, 0.1431, 0.0845,  ..., 0.0877, 0.1042, 0.1166],\n",
      "        [0.0977, 0.1077, 0.0754,  ..., 0.1007, 0.0949, 0.1431],\n",
      "        [0.1056, 0.1029, 0.0791,  ..., 0.1225, 0.1286, 0.1064],\n",
      "        ...,\n",
      "        [0.0906, 0.1142, 0.1210,  ..., 0.0875, 0.1326, 0.0891],\n",
      "        [0.0933, 0.0878, 0.0975,  ..., 0.0963, 0.0956, 0.0940],\n",
      "        [0.1025, 0.0914, 0.1287,  ..., 0.0891, 0.1246, 0.0858]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 2.7031e-01, -9.8458e-02,  1.8606e-01,  2.8362e-01, -1.8800e-01,\n",
      "          8.9182e-02, -3.4007e-01,  5.1126e-02,  4.9755e-01, -1.2593e-01],\n",
      "        [ 9.8644e-02,  2.4031e-02, -3.7482e-04,  4.7210e-01, -1.8669e-01,\n",
      "         -1.0449e-01,  3.8025e-02,  1.4427e-01,  3.7104e-01,  4.3636e-02]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[0.1195, 0.0827, 0.1099,  ..., 0.0960, 0.1500, 0.0804],\n",
      "        [0.0990, 0.0919, 0.0897,  ..., 0.1036, 0.1300, 0.0937],\n",
      "        [0.0979, 0.1227, 0.0901,  ..., 0.1132, 0.0966, 0.0918],\n",
      "        ...,\n",
      "        [0.1250, 0.1013, 0.1095,  ..., 0.1024, 0.1201, 0.0880],\n",
      "        [0.0800, 0.0889, 0.1054,  ..., 0.0976, 0.0954, 0.0859],\n",
      "        [0.1001, 0.0925, 0.0807,  ..., 0.1250, 0.0987, 0.1092]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.0299,  0.0440, -0.2351,  0.1441,  0.0780, -0.0894, -0.2665,  0.0433,\n",
      "         -0.0838,  0.1210],\n",
      "        [ 0.0035, -0.1837, -0.0556,  0.2792, -0.0978, -0.0794,  0.0729,  0.2059,\n",
      "          0.0254, -0.1000]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.1043, 0.1058, 0.0801,  ..., 0.1057, 0.0931, 0.1143],\n",
      "        [0.0987, 0.0818, 0.0930,  ..., 0.1208, 0.1009, 0.0890],\n",
      "        [0.1106, 0.0941, 0.0807,  ..., 0.1099, 0.0810, 0.1252],\n",
      "        ...,\n",
      "        [0.1073, 0.0893, 0.0908,  ..., 0.1066, 0.0870, 0.1189],\n",
      "        [0.1023, 0.0970, 0.0689,  ..., 0.0984, 0.1264, 0.1240],\n",
      "        [0.1156, 0.1028, 0.1051,  ..., 0.1001, 0.1010, 0.0855]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.0440, -0.0970, -0.1701,  0.0818, -0.1266, -0.1026, -0.0829,  0.0446,\n",
      "         -0.2090,  0.0262],\n",
      "        [ 0.0969,  0.0646,  0.1216,  0.2597,  0.0052,  0.1137, -0.2747, -0.0048,\n",
      "         -0.0536,  0.0816]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.1104, 0.0958, 0.0891,  ..., 0.1104, 0.0857, 0.1084],\n",
      "        [0.1048, 0.1015, 0.1075,  ..., 0.0947, 0.0902, 0.1033],\n",
      "        [0.1040, 0.1098, 0.1110,  ..., 0.0866, 0.1008, 0.1220],\n",
      "        ...,\n",
      "        [0.1168, 0.0952, 0.0914,  ..., 0.0917, 0.0878, 0.0970],\n",
      "        [0.1106, 0.0962, 0.0935,  ..., 0.0965, 0.1089, 0.1002],\n",
      "        [0.0903, 0.1019, 0.1216,  ..., 0.1106, 0.0759, 0.1021]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[-0.0379,  0.0668, -0.2307,  0.1596, -0.0602, -0.0041, -0.0509,  0.0174,\n",
      "          0.0515, -0.0359],\n",
      "        [-0.1217,  0.0514,  0.2495,  0.0265, -0.1916,  0.1568, -0.0086,  0.0492,\n",
      "          0.2785,  0.0929]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.0970, 0.1077, 0.0800,  ..., 0.1026, 0.1061, 0.0972],\n",
      "        [0.0827, 0.0984, 0.1199,  ..., 0.0981, 0.1234, 0.1025],\n",
      "        [0.1112, 0.1111, 0.1002,  ..., 0.1092, 0.1278, 0.0720],\n",
      "        ...,\n",
      "        [0.1069, 0.0906, 0.0873,  ..., 0.0938, 0.1029, 0.1040],\n",
      "        [0.0885, 0.1212, 0.1006,  ..., 0.0943, 0.1278, 0.0890],\n",
      "        [0.1234, 0.1052, 0.0828,  ..., 0.0758, 0.1061, 0.1124]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.1284,  0.0312, -0.2638,  0.0139,  0.1656,  0.0218, -0.1279,  0.0231,\n",
      "          0.1683,  0.1988],\n",
      "        [-0.1416,  0.3550,  0.1438, -0.0648, -0.0257,  0.2628, -0.4242,  0.2553,\n",
      "          0.2182,  0.1350]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.1087, 0.0986, 0.0734,  ..., 0.0978, 0.1131, 0.1166],\n",
      "        [0.0789, 0.1297, 0.1050,  ..., 0.1174, 0.1131, 0.1041],\n",
      "        [0.0953, 0.0974, 0.1005,  ..., 0.1056, 0.1044, 0.0982],\n",
      "        ...,\n",
      "        [0.0820, 0.1093, 0.1274,  ..., 0.1015, 0.1019, 0.0803],\n",
      "        [0.0872, 0.0986, 0.0894,  ..., 0.1000, 0.0909, 0.1261],\n",
      "        [0.1231, 0.1107, 0.1507,  ..., 0.0902, 0.1175, 0.0915]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.0734, -0.0215,  0.1610,  0.2576,  0.0236,  0.1005, -0.0884, -0.0552,\n",
      "         -0.0649,  0.1469],\n",
      "        [ 0.2002,  0.2932,  0.1114,  0.3468,  0.0925, -0.2574, -0.3160,  0.3610,\n",
      "          0.0177,  0.0986]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.1014, 0.0922, 0.1107,  ..., 0.0892, 0.0883, 0.1092],\n",
      "        [0.1086, 0.1192, 0.0994,  ..., 0.1275, 0.0905, 0.0981],\n",
      "        [0.1012, 0.1064, 0.0847,  ..., 0.1041, 0.1081, 0.1064],\n",
      "        ...,\n",
      "        [0.1092, 0.0876, 0.0954,  ..., 0.1008, 0.0999, 0.1125],\n",
      "        [0.0940, 0.1164, 0.1011,  ..., 0.0919, 0.1277, 0.0903],\n",
      "        [0.0951, 0.1167, 0.1183,  ..., 0.0851, 0.1213, 0.0840]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[-0.1159,  0.2142, -0.0333,  0.0681, -0.0632,  0.0801, -0.2113, -0.0353,\n",
      "          0.0795,  0.1390],\n",
      "        [-0.0078,  0.0704,  0.0024,  0.1983, -0.0836,  0.2293, -0.3050,  0.1227,\n",
      "          0.0726,  0.0805]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.0873, 0.1215, 0.0949,  ..., 0.0947, 0.1062, 0.1127],\n",
      "        [0.0946, 0.1023, 0.0955,  ..., 0.1078, 0.1025, 0.1033],\n",
      "        [0.0899, 0.0963, 0.1102,  ..., 0.0965, 0.1003, 0.1093],\n",
      "        ...,\n",
      "        [0.1067, 0.0954, 0.1205,  ..., 0.0986, 0.1170, 0.0930],\n",
      "        [0.1141, 0.1054, 0.1129,  ..., 0.0731, 0.0867, 0.1072],\n",
      "        [0.0948, 0.0825, 0.0834,  ..., 0.1165, 0.0982, 0.1065]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.2236,  0.3204,  0.1321,  0.3872, -0.2741, -0.1767, -0.1126,  0.2440,\n",
      "          0.1492,  0.3717],\n",
      "        [ 0.0092,  0.0600,  0.1481,  0.0472,  0.0797, -0.0922, -0.1567, -0.2424,\n",
      "          0.0896,  0.0633]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.1076, 0.1185, 0.0982,  ..., 0.1098, 0.0999, 0.1248],\n",
      "        [0.1002, 0.1054, 0.1151,  ..., 0.0779, 0.1086, 0.1058],\n",
      "        [0.0870, 0.1105, 0.0872,  ..., 0.1093, 0.1194, 0.0997],\n",
      "        ...,\n",
      "        [0.0981, 0.0861, 0.1022,  ..., 0.1061, 0.0848, 0.1136],\n",
      "        [0.0942, 0.1041, 0.1191,  ..., 0.1055, 0.0880, 0.1249],\n",
      "        [0.1099, 0.1006, 0.0946,  ..., 0.0832, 0.1094, 0.0988]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.0529,  0.0878,  0.1053,  0.1902, -0.2759,  0.0344,  0.1009, -0.1187,\n",
      "          0.1947,  0.0768],\n",
      "        [ 0.0078,  0.1746, -0.1846,  0.2055,  0.0882, -0.1561, -0.2341,  0.1726,\n",
      "          0.2194,  0.1586]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.0999, 0.1035, 0.1053,  ..., 0.0842, 0.1152, 0.1024],\n",
      "        [0.0951, 0.1123, 0.0784,  ..., 0.1121, 0.1175, 0.1105],\n",
      "        [0.1107, 0.1013, 0.0897,  ..., 0.0871, 0.1016, 0.1058],\n",
      "        ...,\n",
      "        [0.1115, 0.0939, 0.0811,  ..., 0.1066, 0.1134, 0.1145],\n",
      "        [0.1008, 0.0845, 0.0948,  ..., 0.1007, 0.0875, 0.1283],\n",
      "        [0.0899, 0.1096, 0.0910,  ..., 0.0974, 0.1128, 0.0969]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.4019,  0.2052,  0.1248,  0.1960, -0.1174, -0.2460, -0.0809,  0.0757,\n",
      "          0.1732, -0.0669],\n",
      "        [-0.0341,  0.0253, -0.1597,  0.1332, -0.2234,  0.0591, -0.2413, -0.0665,\n",
      "          0.1170, -0.0102]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.1375, 0.1130, 0.1042,  ..., 0.0992, 0.1094, 0.0861],\n",
      "        [0.0998, 0.1059, 0.0880,  ..., 0.0966, 0.1161, 0.1022],\n",
      "        [0.1096, 0.0891, 0.0929,  ..., 0.0931, 0.0999, 0.1034],\n",
      "        ...,\n",
      "        [0.1213, 0.1174, 0.0914,  ..., 0.1131, 0.0942, 0.0974],\n",
      "        [0.0939, 0.1296, 0.0852,  ..., 0.1105, 0.0771, 0.0921],\n",
      "        [0.1115, 0.0887, 0.0944,  ..., 0.1058, 0.1225, 0.0921]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.0363,  0.1558, -0.0574,  0.2614, -0.2123, -0.0094, -0.1083,  0.1418,\n",
      "          0.2427, -0.2115],\n",
      "        [ 0.1341,  0.0375,  0.2853,  0.2579, -0.0886,  0.1387, -0.0894,  0.1422,\n",
      "         -0.0254, -0.2013]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.0999, 0.1126, 0.0909,  ..., 0.1110, 0.1228, 0.0780],\n",
      "        [0.1066, 0.0968, 0.1240,  ..., 0.1074, 0.0909, 0.0762],\n",
      "        [0.0984, 0.1093, 0.1379,  ..., 0.0878, 0.0903, 0.1021],\n",
      "        ...,\n",
      "        [0.1095, 0.1018, 0.0897,  ..., 0.1111, 0.1001, 0.1029],\n",
      "        [0.1044, 0.0890, 0.0862,  ..., 0.0945, 0.1044, 0.1098],\n",
      "        [0.1275, 0.0967, 0.0839,  ..., 0.0814, 0.1075, 0.0877]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.0821,  0.0605,  0.1708,  0.0812, -0.2310,  0.2302, -0.0144, -0.2129,\n",
      "         -0.1266,  0.2254],\n",
      "        [ 0.0182,  0.0178, -0.2007,  0.0570, -0.1009, -0.1225, -0.1996,  0.0157,\n",
      "         -0.0880, -0.0225]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.1044, 0.1022, 0.1141,  ..., 0.0777, 0.0847, 0.1205],\n",
      "        [0.1080, 0.1079, 0.0868,  ..., 0.1077, 0.0971, 0.1037],\n",
      "        [0.0970, 0.1237, 0.1048,  ..., 0.0955, 0.1044, 0.0949],\n",
      "        ...,\n",
      "        [0.1034, 0.0964, 0.0871,  ..., 0.0960, 0.1139, 0.1209],\n",
      "        [0.0902, 0.1131, 0.0802,  ..., 0.1120, 0.1142, 0.1212],\n",
      "        [0.0846, 0.1155, 0.0894,  ..., 0.0942, 0.0903, 0.1617]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.0843, -0.0017, -0.0592,  0.4646, -0.0164,  0.0196, -0.1476, -0.1177,\n",
      "         -0.0420,  0.0905],\n",
      "        [-0.0960, -0.0537, -0.0987,  0.1962, -0.1895,  0.1027, -0.1825,  0.0153,\n",
      "          0.1950, -0.3092]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.1043, 0.0957, 0.0904,  ..., 0.0852, 0.0919, 0.1050],\n",
      "        [0.0935, 0.0976, 0.0933,  ..., 0.1046, 0.1251, 0.0756],\n",
      "        [0.0988, 0.1237, 0.0900,  ..., 0.0889, 0.0995, 0.1144],\n",
      "        ...,\n",
      "        [0.0918, 0.1174, 0.1226,  ..., 0.0959, 0.0981, 0.0975],\n",
      "        [0.0771, 0.1287, 0.1301,  ..., 0.0869, 0.1137, 0.1012],\n",
      "        [0.1172, 0.1166, 0.1062,  ..., 0.0827, 0.0878, 0.1083]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.1045,  0.1617, -0.2719,  0.5699,  0.0778, -0.0292,  0.0138,  0.0700,\n",
      "          0.0558,  0.3728],\n",
      "        [ 0.0947,  0.1646,  0.2506,  0.0621, -0.1560, -0.3122,  0.2608, -0.0064,\n",
      "          0.1152, -0.0637]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.0968, 0.1025, 0.0665,  ..., 0.0936, 0.0922, 0.1266],\n",
      "        [0.1040, 0.1116, 0.1216,  ..., 0.0940, 0.1062, 0.0888],\n",
      "        [0.0999, 0.1060, 0.0932,  ..., 0.0874, 0.1329, 0.0966],\n",
      "        ...,\n",
      "        [0.0897, 0.1037, 0.0926,  ..., 0.1072, 0.1198, 0.1005],\n",
      "        [0.1194, 0.1212, 0.1113,  ..., 0.0948, 0.1070, 0.0721],\n",
      "        [0.1078, 0.1080, 0.1055,  ..., 0.1005, 0.1053, 0.0811]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[-0.0946,  0.1226,  0.0459,  0.2428, -0.0011,  0.0527, -0.0199,  0.0010,\n",
      "          0.2610,  0.0383],\n",
      "        [ 0.0651,  0.2172,  0.3361,  0.2109, -0.3818,  0.0687, -0.0778, -0.1629,\n",
      "          0.2145, -0.0981]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.0848, 0.1053, 0.0975,  ..., 0.0933, 0.1210, 0.0968],\n",
      "        [0.1005, 0.1170, 0.1318,  ..., 0.0800, 0.1167, 0.0854],\n",
      "        [0.1131, 0.0886, 0.0774,  ..., 0.0982, 0.1038, 0.1097],\n",
      "        ...,\n",
      "        [0.1022, 0.0932, 0.0965,  ..., 0.0952, 0.0791, 0.1286],\n",
      "        [0.0928, 0.1207, 0.0808,  ..., 0.0953, 0.1284, 0.1071],\n",
      "        [0.0977, 0.1286, 0.1128,  ..., 0.0617, 0.1043, 0.1240]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.2005, -0.0179,  0.0610,  0.2485, -0.0035, -0.0596,  0.0341,  0.0202,\n",
      "          0.0072,  0.1514],\n",
      "        [ 0.1450, -0.0017,  0.0734,  0.0055,  0.0715,  0.0303, -0.2662,  0.0597,\n",
      "          0.0112,  0.2759]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.1141, 0.0917, 0.0992,  ..., 0.0952, 0.0940, 0.1086],\n",
      "        [0.1101, 0.0951, 0.1025,  ..., 0.1011, 0.0963, 0.1255],\n",
      "        [0.1082, 0.1079, 0.0964,  ..., 0.0991, 0.1371, 0.0908],\n",
      "        ...,\n",
      "        [0.0941, 0.1186, 0.0967,  ..., 0.1005, 0.0991, 0.1158],\n",
      "        [0.0974, 0.0994, 0.1020,  ..., 0.1000, 0.1110, 0.1027],\n",
      "        [0.0936, 0.1113, 0.1136,  ..., 0.0900, 0.1341, 0.0664]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.1862,  0.0077, -0.1007,  0.3908, -0.1537, -0.0580, -0.0478,  0.3158,\n",
      "          0.0207, -0.1789],\n",
      "        [-0.1338,  0.2198,  0.3942,  0.3317, -0.3555,  0.0121,  0.1643,  0.0883,\n",
      "          0.1141,  0.0751]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.1139, 0.0953, 0.0855,  ..., 0.1296, 0.0965, 0.0791],\n",
      "        [0.0782, 0.1114, 0.1327,  ..., 0.0977, 0.1003, 0.0964],\n",
      "        [0.0918, 0.1030, 0.0801,  ..., 0.1075, 0.1062, 0.1031],\n",
      "        ...,\n",
      "        [0.1330, 0.1069, 0.0754,  ..., 0.0847, 0.1104, 0.0919],\n",
      "        [0.1032, 0.1138, 0.1164,  ..., 0.0786, 0.1089, 0.0923],\n",
      "        [0.1127, 0.1064, 0.1158,  ..., 0.1172, 0.1031, 0.1006]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.0796,  0.0263, -0.0025,  0.2462,  0.1667,  0.1426, -0.0866, -0.0494,\n",
      "          0.1195, -0.0011],\n",
      "        [ 0.1384, -0.0299,  0.1813,  0.3944, -0.2636,  0.0577, -0.0604,  0.1448,\n",
      "          0.2828, -0.0586]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.1011, 0.0958, 0.0931,  ..., 0.0888, 0.1052, 0.0932],\n",
      "        [0.1044, 0.0883, 0.1090,  ..., 0.1051, 0.1207, 0.0858],\n",
      "        [0.1011, 0.1134, 0.0683,  ..., 0.1191, 0.0832, 0.1180],\n",
      "        ...,\n",
      "        [0.1226, 0.0899, 0.1042,  ..., 0.0830, 0.1204, 0.1010],\n",
      "        [0.0963, 0.0949, 0.1107,  ..., 0.1062, 0.0882, 0.1038],\n",
      "        [0.0996, 0.0979, 0.0910,  ..., 0.0924, 0.1141, 0.1141]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.2752,  0.1593, -0.1078,  0.1337, -0.2015,  0.0396, -0.0663,  0.2105,\n",
      "          0.0278, -0.1534],\n",
      "        [-0.0591, -0.0517,  0.1725,  0.4489, -0.0140,  0.2918, -0.2566, -0.0893,\n",
      "         -0.0021, -0.1459]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.1261, 0.1123, 0.0860,  ..., 0.1182, 0.0984, 0.0821],\n",
      "        [0.0896, 0.0902, 0.1129,  ..., 0.0869, 0.0948, 0.0821],\n",
      "        [0.1094, 0.0999, 0.0819,  ..., 0.1076, 0.1028, 0.0998],\n",
      "        ...,\n",
      "        [0.0956, 0.1159, 0.1017,  ..., 0.0664, 0.1152, 0.1304],\n",
      "        [0.1211, 0.1268, 0.1268,  ..., 0.0938, 0.1119, 0.0802],\n",
      "        [0.0949, 0.0903, 0.0907,  ..., 0.1042, 0.0957, 0.1325]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n"
     ]
    }
   ],
   "source": [
    "for image, label in train_data:\n",
    "    output = model(image)\n",
    "    print(output[:2])\n",
    "    real_output = F.softmax(output, dim = 1)\n",
    "    print(real_output)\n",
    "    print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_output = F.softmax(output, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.1261, 0.1123, 0.0860,  ..., 0.1182, 0.0984, 0.0821],\n",
       "        [0.0896, 0.0902, 0.1129,  ..., 0.0869, 0.0948, 0.0821],\n",
       "        [0.1094, 0.0999, 0.0819,  ..., 0.1076, 0.1028, 0.0998],\n",
       "        ...,\n",
       "        [0.0956, 0.1159, 0.1017,  ..., 0.0664, 0.1152, 0.1304],\n",
       "        [0.1211, 0.1268, 0.1268,  ..., 0.0938, 0.1119, 0.0802],\n",
       "        [0.0949, 0.0903, 0.0907,  ..., 0.1042, 0.0957, 0.1325]],\n",
       "       grad_fn=<SoftmaxBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "real_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.sum(real_output[:5]).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([0, 3, 3, 0, 1, 3, 8, 3, 3, 0, 5, 1, 0, 3, 3, 3, 2, 9, 3, 3, 3, 1, 8, 8,\n",
      "        9, 0, 2, 8, 3, 3, 2, 3, 7, 8, 2, 9, 3, 8, 8, 1, 3, 3, 0, 1, 3, 3, 5, 9,\n",
      "        3, 2])\n",
      "REAL LABELS\n",
      "tensor([2, 3, 7, 6, 8, 8, 4, 5, 1, 2, 2, 9, 3, 1, 2, 8, 7, 7, 1, 0, 2, 6, 2, 7,\n",
      "        4, 9, 6, 4, 9, 8, 2, 8, 5, 2, 6, 9, 8, 6, 4, 6, 5, 8, 1, 0, 1, 7, 3, 1,\n",
      "        1, 6])\n"
     ]
    }
   ],
   "source": [
    "best_prob, pred = torch.max(real_output, dim = 1)\n",
    "# print(best_prob)\n",
    "print(pred[:50])\n",
    "print(\"REAL LABELS\")\n",
    "print(label[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.122"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "#creating evaluation metric and loss function\n",
    "def accuracy(predicted, actual_label):\n",
    "    return torch.sum(predicted == actual_label).item() / len(predicted)\n",
    "\n",
    "accuracy(pred, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loss_fn(pred, label):\n",
    "    loss_fn  = F.cross_entropy\n",
    "    loss = loss_fn(pred, label)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.SGD(model.parameters(), lr = 0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def train_loss(model, loss_fn,  train_dl, optimizer = None, metric = None):\n",
    "    for image, label in data_dl:\n",
    "        pred = model(image)\n",
    "        loss = loss_fn(pred, label)\n",
    "        real_output = F.softmax(pred)\n",
    "        best_prob, pred = torch.max(real_output, dim = 1)\n",
    "        \n",
    "        if optimizer is not None:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        metric_result = None\n",
    "        if metric is not None:\n",
    "            metric_result = metric(pred, label)\n",
    "\n",
    "        return loss.item(), len(image), metric_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ipykernel_launcher:6: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1.7305145263671875, 500, 0.728)"
      ]
     },
     "metadata": {},
     "execution_count": 134
    }
   ],
   "source": [
    "train_loss(model, loss_fn,  train_data, optimizer = optim, metric = accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_loss(model, loss_fn, val_dl, metric = None):\n",
    "    losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, label in val_dl:\n",
    "            pred = model(pred)\n",
    "            loss = loss_fn(pred, label)\n",
    "            losses.append(loss)\n",
    "            real_output = F.softmax(pred)\n",
    "            best_prob, pred = torch.max(real_output, dim = 1)\n",
    "\n",
    "            metric_result = None\n",
    "            if metric is not None:\n",
    "                metric_result = metric(pred, label)\n",
    "\n",
    "            return loss.item(), len(image), metric_result\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "interpreter": {
   "hash": "9d3bae0a0f66551680ef8a166f6b92cc2774d5d7901f027deb7bb883ed06d5ae"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}