{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasets = MNIST(root = 'classification data/', download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = MNIST(root = 'classification data/', train = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "len(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = MNIST(root = 'classification data/', train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=L size=28x28 at 0x1DA960DAA08>, 4)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "datasets[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=L size=28x28 at 0x1DA96101088>, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "test_data[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = MNIST(root = 'classification data/', train = True, transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "img, label = datasets[2]\n",
    "print(img.shape)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = MNIST(root = 'classification data/', train = False, transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "img, label = datasets[200]\n",
    "print(img.shape)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating training datasets and validation datasets\n",
    "def indices_selector(factor, data_num):\n",
    "    val_num_of_indices = int(factor * data_num)\n",
    "    total_indices = np.random.permutation(data_num)\n",
    "    return total_indices[val_num_of_indices:], total_indices[:val_num_of_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([43977, 44013, 58357, ..., 16876, 27883, 17875]),\n",
       " array([ 9270, 21259, 40454, ..., 28492, 33663, 27840]))"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "indices_selector(0.2, len(datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, val_indices = indices_selector(0.2, len(datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "train_data = DataLoader(datasets, batch_size, sampler = train_sampler)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "val_data = DataLoader(datasets, batch_size, sampler = val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_data:\n",
    "    print(x.shape)\n",
    "#     print(y)\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28*28\n",
    "ouput_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating model\n",
    "class MNIST_Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, ouput_classes)\n",
    "        \n",
    "    def forward(self, input_reshape):\n",
    "        input_reshape = input_reshape.reshape(-1, 28*28)\n",
    "        output = self.linear(input_reshape)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNIST_Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ")\n",
      "tensor([[0.1133, 0.0890, 0.0977,  ..., 0.0996, 0.0758, 0.0869],\n",
      "        [0.1090, 0.0888, 0.0864,  ..., 0.1033, 0.0844, 0.0956],\n",
      "        [0.1269, 0.0905, 0.0948,  ..., 0.1127, 0.0818, 0.0945],\n",
      "        ...,\n",
      "        [0.1107, 0.0946, 0.0950,  ..., 0.1165, 0.0890, 0.0892],\n",
      "        [0.1093, 0.0982, 0.1042,  ..., 0.1132, 0.0744, 0.0842],\n",
      "        [0.0844, 0.0688, 0.1224,  ..., 0.1309, 0.0651, 0.0929]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.0234, -0.0928,  0.0643,  0.0270, -0.0086, -0.1224, -0.0767,  0.2786,\n",
      "         -0.1293, -0.1425],\n",
      "        [ 0.0597,  0.0318, -0.0655,  0.0368,  0.0936,  0.0927,  0.0801, -0.0132,\n",
      "         -0.2604, -0.1650]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.1034, 0.0921, 0.1077,  ..., 0.1335, 0.0888, 0.0876],\n",
      "        [0.1067, 0.1037, 0.0941,  ..., 0.0992, 0.0774, 0.0852],\n",
      "        [0.1100, 0.1020, 0.1086,  ..., 0.1287, 0.0685, 0.0778],\n",
      "        ...,\n",
      "        [0.1100, 0.0635, 0.0930,  ..., 0.1287, 0.0728, 0.0808],\n",
      "        [0.1134, 0.0992, 0.1022,  ..., 0.1084, 0.0715, 0.0879],\n",
      "        [0.1094, 0.0934, 0.0936,  ..., 0.1180, 0.0804, 0.0840]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.2333, -0.0782,  0.0199,  0.1552, -0.3004, -0.0392,  0.1618,  0.1822,\n",
      "         -0.3597, -0.0441],\n",
      "        [ 0.2106, -0.4405,  0.2437,  0.0156,  0.1444,  0.2969,  0.4754,  0.4730,\n",
      "          0.0085,  0.0406]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.1249, 0.0915, 0.1009,  ..., 0.1187, 0.0690, 0.0947],\n",
      "        [0.1034, 0.0539, 0.1069,  ..., 0.1345, 0.0845, 0.0873],\n",
      "        [0.1115, 0.0783, 0.0947,  ..., 0.1128, 0.0836, 0.1051],\n",
      "        ...,\n",
      "        [0.1157, 0.0942, 0.1088,  ..., 0.1128, 0.0670, 0.0873],\n",
      "        [0.0868, 0.0352, 0.1221,  ..., 0.1912, 0.0736, 0.0966],\n",
      "        [0.1128, 0.0745, 0.1037,  ..., 0.1458, 0.0688, 0.0857]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.0113,  0.0601, -0.1227,  0.0752,  0.0894, -0.0550, -0.0031,  0.0833,\n",
      "         -0.0990, -0.1548],\n",
      "        [ 0.1006, -0.5505, -0.1802, -0.3198, -0.0041,  0.0877,  0.3653,  0.4082,\n",
      "          0.0437, -0.0316]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.1019, 0.1070, 0.0891,  ..., 0.1095, 0.0913, 0.0863],\n",
      "        [0.1075, 0.0560, 0.0812,  ..., 0.1462, 0.1015, 0.0942],\n",
      "        [0.1170, 0.0825, 0.1209,  ..., 0.1318, 0.0740, 0.0757],\n",
      "        ...,\n",
      "        [0.1036, 0.0612, 0.1057,  ..., 0.1726, 0.0538, 0.0852],\n",
      "        [0.1181, 0.0514, 0.1205,  ..., 0.1183, 0.0601, 0.0825],\n",
      "        [0.1024, 0.0776, 0.1318,  ..., 0.1037, 0.0758, 0.0723]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.2814, -0.1220, -0.0612,  0.0197,  0.0909, -0.0437,  0.2355, -0.0997,\n",
      "         -0.3277, -0.1011],\n",
      "        [ 0.0386, -0.0979, -0.0202, -0.1261,  0.1855, -0.0660, -0.1015, -0.0314,\n",
      "         -0.2617, -0.1022]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.1323, 0.0884, 0.0939,  ..., 0.0903, 0.0719, 0.0902],\n",
      "        [0.1095, 0.0955, 0.1032,  ..., 0.1021, 0.0811, 0.0951],\n",
      "        [0.0901, 0.0686, 0.0939,  ..., 0.1289, 0.1020, 0.0817],\n",
      "        ...,\n",
      "        [0.1096, 0.0999, 0.0983,  ..., 0.0992, 0.0904, 0.0989],\n",
      "        [0.1030, 0.0785, 0.1003,  ..., 0.0924, 0.0872, 0.0843],\n",
      "        [0.1169, 0.0852, 0.0958,  ..., 0.1067, 0.0885, 0.0831]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.1480, -0.3236, -0.0455, -0.0629,  0.0464, -0.0553,  0.2886,  0.3017,\n",
      "         -0.2160, -0.2139],\n",
      "        [-0.0907, -0.3630,  0.0734,  0.1016, -0.0177,  0.1874,  0.3756,  0.3993,\n",
      "          0.2013,  0.1837]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.1151, 0.0718, 0.0949,  ..., 0.1343, 0.0800, 0.0802],\n",
      "        [0.0805, 0.0613, 0.0948,  ..., 0.1313, 0.1077, 0.1059],\n",
      "        [0.1133, 0.0942, 0.0813,  ..., 0.0946, 0.0987, 0.0995],\n",
      "        ...,\n",
      "        [0.1184, 0.0876, 0.1051,  ..., 0.1407, 0.0702, 0.0918],\n",
      "        [0.1266, 0.0924, 0.0715,  ..., 0.1138, 0.0850, 0.0819],\n",
      "        [0.1002, 0.0796, 0.1108,  ..., 0.0845, 0.0872, 0.0847]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.0486, -0.2030, -0.0053, -0.2429, -0.2375, -0.1074,  0.1987, -0.1070,\n",
      "         -0.1356, -0.1441],\n",
      "        [ 0.2722, -0.0224, -0.1589,  0.0349,  0.0616,  0.0807,  0.3703, -0.0542,\n",
      "         -0.2826, -0.0785]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.1142, 0.0888, 0.1082,  ..., 0.0978, 0.0950, 0.0942],\n",
      "        [0.1262, 0.0940, 0.0820,  ..., 0.0911, 0.0725, 0.0889],\n",
      "        [0.1228, 0.1023, 0.0927,  ..., 0.1139, 0.0757, 0.1010],\n",
      "        ...,\n",
      "        [0.1118, 0.0723, 0.0826,  ..., 0.1268, 0.0816, 0.0896],\n",
      "        [0.1049, 0.0907, 0.1173,  ..., 0.1319, 0.0780, 0.0769],\n",
      "        [0.1231, 0.1014, 0.1020,  ..., 0.1004, 0.0816, 0.0758]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.3200, -0.2396, -0.0097, -0.1394, -0.1396, -0.0609,  0.2096,  0.1357,\n",
      "         -0.3793, -0.1600],\n",
      "        [-0.0139, -0.0333, -0.0179, -0.0872, -0.0894,  0.1108,  0.1179, -0.2115,\n",
      "         -0.3556, -0.0879]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.1412, 0.0807, 0.1016,  ..., 0.1175, 0.0702, 0.0874],\n",
      "        [0.1045, 0.1025, 0.1041,  ..., 0.0858, 0.0743, 0.0971],\n",
      "        [0.1297, 0.0847, 0.0915,  ..., 0.1574, 0.0701, 0.0935],\n",
      "        ...,\n",
      "        [0.1082, 0.0910, 0.1020,  ..., 0.1165, 0.1111, 0.0864],\n",
      "        [0.0949, 0.0942, 0.1073,  ..., 0.1058, 0.0785, 0.0926],\n",
      "        [0.0854, 0.0916, 0.1002,  ..., 0.1382, 0.0648, 0.0801]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.0616, -0.0588,  0.0036,  0.0155,  0.1096,  0.0650,  0.0205,  0.0891,\n",
      "         -0.3300, -0.1020],\n",
      "        [ 0.0740, -0.1017, -0.0565, -0.0401, -0.1999, -0.0493,  0.1231,  0.0864,\n",
      "         -0.1503, -0.0238]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.1070, 0.0948, 0.1009,  ..., 0.1099, 0.0723, 0.0908],\n",
      "        [0.1108, 0.0930, 0.0973,  ..., 0.1122, 0.0886, 0.1005],\n",
      "        [0.1076, 0.1039, 0.0995,  ..., 0.0986, 0.0800, 0.0852],\n",
      "        ...,\n",
      "        [0.1130, 0.0663, 0.1096,  ..., 0.1248, 0.0671, 0.1097],\n",
      "        [0.0971, 0.0648, 0.1049,  ..., 0.1773, 0.0525, 0.0773],\n",
      "        [0.1082, 0.0766, 0.0880,  ..., 0.1003, 0.0953, 0.1041]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[-0.0799, -0.3463,  0.2340, -0.1135,  0.1045, -0.0506, -0.1230,  0.0319,\n",
      "         -0.4392, -0.0983],\n",
      "        [ 0.0608, -0.0670, -0.1275,  0.0330, -0.1082,  0.1208,  0.3045,  0.1473,\n",
      "         -0.1983, -0.1136]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.0991, 0.0759, 0.1357,  ..., 0.1108, 0.0692, 0.0973],\n",
      "        [0.1045, 0.0920, 0.0866,  ..., 0.1140, 0.0807, 0.0878],\n",
      "        [0.1321, 0.0704, 0.0942,  ..., 0.1194, 0.0715, 0.0958],\n",
      "        ...,\n",
      "        [0.1088, 0.0637, 0.1363,  ..., 0.1047, 0.0909, 0.0759],\n",
      "        [0.1033, 0.0586, 0.0942,  ..., 0.1472, 0.0900, 0.0799],\n",
      "        [0.1200, 0.1015, 0.1025,  ..., 0.1207, 0.0898, 0.0884]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.2398, -0.3452,  0.0595, -0.0616, -0.0673, -0.0837,  0.3122,  0.2552,\n",
      "         -0.0584,  0.1480],\n",
      "        [ 0.2950, -0.4443,  0.1885,  0.2968,  0.0558, -0.2311,  0.5786,  0.4804,\n",
      "         -0.3779, -0.0797]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.1200, 0.0668, 0.1002,  ..., 0.1218, 0.0890, 0.1094],\n",
      "        [0.1178, 0.0563, 0.1059,  ..., 0.1418, 0.0601, 0.0810],\n",
      "        [0.0963, 0.0807, 0.1283,  ..., 0.1101, 0.0747, 0.0962],\n",
      "        ...,\n",
      "        [0.1354, 0.0567, 0.1118,  ..., 0.1105, 0.0774, 0.0960],\n",
      "        [0.0995, 0.0963, 0.0974,  ..., 0.1029, 0.1008, 0.1020],\n",
      "        [0.1030, 0.0952, 0.1041,  ..., 0.1037, 0.0854, 0.0931]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[-0.0749,  0.0329, -0.1041, -0.0363,  0.0695,  0.0635,  0.0381,  0.1136,\n",
      "         -0.1117,  0.0125],\n",
      "        [ 0.2675, -0.3578,  0.1146, -0.0524, -0.1240, -0.1147,  0.3234,  0.5925,\n",
      "         -0.2640, -0.1511]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.0925, 0.1030, 0.0898,  ..., 0.1117, 0.0892, 0.1009],\n",
      "        [0.1225, 0.0655, 0.1051,  ..., 0.1695, 0.0720, 0.0806],\n",
      "        [0.1089, 0.0852, 0.1045,  ..., 0.1127, 0.0842, 0.0863],\n",
      "        ...,\n",
      "        [0.0928, 0.0738, 0.1135,  ..., 0.1275, 0.0993, 0.0814],\n",
      "        [0.1475, 0.0771, 0.0882,  ..., 0.1166, 0.0732, 0.0833],\n",
      "        [0.1184, 0.0780, 0.1031,  ..., 0.1063, 0.0669, 0.1079]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.1165, -0.3324,  0.1449,  0.2381,  0.0212, -0.0016,  0.1173,  0.5983,\n",
      "         -0.4480, -0.3546],\n",
      "        [ 0.0759, -0.3376, -0.0151, -0.0540,  0.0093,  0.0053,  0.2550,  0.1566,\n",
      "         -0.1603,  0.2652]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.1063, 0.0679, 0.1094,  ..., 0.1721, 0.0605, 0.0664],\n",
      "        [0.1042, 0.0689, 0.0951,  ..., 0.1129, 0.0823, 0.1259],\n",
      "        [0.0891, 0.0690, 0.1411,  ..., 0.0964, 0.0806, 0.0872],\n",
      "        ...,\n",
      "        [0.1131, 0.1039, 0.0948,  ..., 0.0992, 0.0901, 0.0809],\n",
      "        [0.0967, 0.0910, 0.0919,  ..., 0.1226, 0.0858, 0.1109],\n",
      "        [0.1170, 0.0969, 0.0819,  ..., 0.1005, 0.0733, 0.0769]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.0111,  0.0052,  0.0396, -0.0298,  0.1263, -0.0157, -0.0595,  0.1085,\n",
      "         -0.2993, -0.1883],\n",
      "        [ 0.2607, -0.0398, -0.1785, -0.1214, -0.1709, -0.0213,  0.2083,  0.0123,\n",
      "         -0.1537, -0.0457]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.1035, 0.1029, 0.1065,  ..., 0.1141, 0.0759, 0.0848],\n",
      "        [0.1316, 0.0975, 0.0848,  ..., 0.1027, 0.0870, 0.0969],\n",
      "        [0.0883, 0.0907, 0.1012,  ..., 0.1132, 0.0804, 0.0966],\n",
      "        ...,\n",
      "        [0.1081, 0.0931, 0.0875,  ..., 0.1087, 0.0877, 0.0802],\n",
      "        [0.1295, 0.1034, 0.0807,  ..., 0.1244, 0.0692, 0.0802],\n",
      "        [0.1106, 0.0790, 0.1112,  ..., 0.1232, 0.0658, 0.0657]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.1546,  0.0528,  0.2438, -0.0680, -0.0286,  0.0558,  0.3583,  0.2444,\n",
      "         -0.1439, -0.1994],\n",
      "        [-0.0840, -0.2433,  0.0617,  0.0330, -0.0536,  0.2991,  0.3822,  0.6256,\n",
      "         -0.0360,  0.0990]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.1075, 0.0971, 0.1176,  ..., 0.1176, 0.0798, 0.0755],\n",
      "        [0.0799, 0.0682, 0.0925,  ..., 0.1625, 0.0839, 0.0960],\n",
      "        [0.1215, 0.0724, 0.1246,  ..., 0.1122, 0.0795, 0.0884],\n",
      "        ...,\n",
      "        [0.0966, 0.0772, 0.1197,  ..., 0.1021, 0.0773, 0.0862],\n",
      "        [0.1258, 0.0875, 0.0858,  ..., 0.1250, 0.0795, 0.0970],\n",
      "        [0.1163, 0.0891, 0.0921,  ..., 0.1420, 0.0769, 0.0832]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.0552, -0.4569,  0.3122,  0.1853, -0.0493, -0.0362,  0.7106,  0.3315,\n",
      "         -0.3534, -0.1458],\n",
      "        [ 0.1408, -0.2034,  0.0455, -0.2870, -0.0527,  0.1338,  0.1432,  0.0714,\n",
      "         -0.1300, -0.1513]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.0946, 0.0567, 0.1223,  ..., 0.1247, 0.0629, 0.0774],\n",
      "        [0.1172, 0.0831, 0.1066,  ..., 0.1094, 0.0894, 0.0875],\n",
      "        [0.1167, 0.0727, 0.1017,  ..., 0.1375, 0.0668, 0.0885],\n",
      "        ...,\n",
      "        [0.1404, 0.1089, 0.0881,  ..., 0.1110, 0.0750, 0.0878],\n",
      "        [0.0936, 0.0849, 0.0886,  ..., 0.1276, 0.0970, 0.1024],\n",
      "        [0.1251, 0.0804, 0.0783,  ..., 0.1493, 0.0763, 0.0739]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.3925, -0.0573,  0.0973,  0.1705, -0.2995,  0.0540,  0.2999,  0.0853,\n",
      "         -0.3088, -0.2228],\n",
      "        [ 0.1853, -0.2042, -0.0367, -0.0409, -0.0157, -0.0593,  0.6208,  0.3969,\n",
      "         -0.0543,  0.1064]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.1412, 0.0901, 0.1051,  ..., 0.1039, 0.0700, 0.0763],\n",
      "        [0.1067, 0.0723, 0.0855,  ..., 0.1319, 0.0840, 0.0986],\n",
      "        [0.1050, 0.0794, 0.1115,  ..., 0.1127, 0.0753, 0.1072],\n",
      "        ...,\n",
      "        [0.1416, 0.1007, 0.0963,  ..., 0.1104, 0.0789, 0.0930],\n",
      "        [0.1019, 0.0794, 0.0951,  ..., 0.1309, 0.0893, 0.0764],\n",
      "        [0.0883, 0.0584, 0.1114,  ..., 0.1494, 0.0722, 0.0769]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.1937, -0.0583, -0.2751,  0.0027, -0.0868, -0.1422,  0.1327, -0.0974,\n",
      "         -0.1027, -0.0217],\n",
      "        [ 0.1369, -0.5324, -0.0042,  0.0622,  0.0308,  0.3385,  0.5414,  0.0608,\n",
      "         -0.0639, -0.2444]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.1260, 0.0979, 0.0788,  ..., 0.0942, 0.0937, 0.1016],\n",
      "        [0.1069, 0.0547, 0.0928,  ..., 0.0990, 0.0874, 0.0730],\n",
      "        [0.1222, 0.0971, 0.0983,  ..., 0.1244, 0.0892, 0.0818],\n",
      "        ...,\n",
      "        [0.1039, 0.0736, 0.0984,  ..., 0.1048, 0.0600, 0.0982],\n",
      "        [0.0932, 0.0837, 0.0876,  ..., 0.1167, 0.0698, 0.0851],\n",
      "        [0.1323, 0.0605, 0.1056,  ..., 0.1230, 0.0847, 0.0818]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.2375, -0.4305,  0.1464, -0.0725, -0.1175,  0.0889,  0.2040,  0.1080,\n",
      "         -0.4228, -0.0701],\n",
      "        [-0.1119, -0.1644,  0.2353, -0.1290,  0.2825, -0.0339,  0.3482,  0.2856,\n",
      "         -0.1663, -0.0743]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.1279, 0.0656, 0.1167,  ..., 0.1124, 0.0661, 0.0940],\n",
      "        [0.0835, 0.0793, 0.1182,  ..., 0.1243, 0.0791, 0.0867],\n",
      "        [0.1071, 0.0542, 0.0871,  ..., 0.1130, 0.0937, 0.0854],\n",
      "        ...,\n",
      "        [0.1076, 0.0611, 0.1312,  ..., 0.1396, 0.0698, 0.0866],\n",
      "        [0.1288, 0.0907, 0.0871,  ..., 0.1327, 0.0840, 0.0975],\n",
      "        [0.1351, 0.0871, 0.0933,  ..., 0.1101, 0.0880, 0.0881]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.2862,  0.0089,  0.1427,  0.1252,  0.2476,  0.0598,  0.2149, -0.0683,\n",
      "         -0.3338, -0.2289],\n",
      "        [ 0.0384, -0.2489, -0.0593,  0.2347,  0.0542,  0.0913,  0.4002,  0.3854,\n",
      "         -0.3049, -0.0577]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.1250, 0.0947, 0.1082,  ..., 0.0877, 0.0672, 0.0747],\n",
      "        [0.0960, 0.0721, 0.0871,  ..., 0.1359, 0.0681, 0.0872],\n",
      "        [0.0983, 0.0651, 0.1189,  ..., 0.1334, 0.0773, 0.0813],\n",
      "        ...,\n",
      "        [0.1172, 0.0838, 0.1184,  ..., 0.1046, 0.0842, 0.0764],\n",
      "        [0.1230, 0.0923, 0.1116,  ..., 0.1321, 0.0627, 0.0734],\n",
      "        [0.1042, 0.0941, 0.0837,  ..., 0.1241, 0.0862, 0.0651]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.1541,  0.0095, -0.0211, -0.0155,  0.1618,  0.0986,  0.0173, -0.0096,\n",
      "         -0.2788, -0.0868],\n",
      "        [ 0.3005, -0.1241, -0.0061,  0.1042,  0.0764,  0.0116,  0.4841,  0.0166,\n",
      "         -0.1221, -0.1416]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.1155, 0.0999, 0.0969,  ..., 0.0981, 0.0749, 0.0908],\n",
      "        [0.1248, 0.0816, 0.0918,  ..., 0.0940, 0.0818, 0.0802],\n",
      "        [0.0891, 0.0868, 0.0958,  ..., 0.1238, 0.0863, 0.0875],\n",
      "        ...,\n",
      "        [0.1098, 0.0763, 0.0762,  ..., 0.1139, 0.0652, 0.0913],\n",
      "        [0.1055, 0.0736, 0.1275,  ..., 0.1272, 0.0716, 0.0826],\n",
      "        [0.1160, 0.0903, 0.0847,  ..., 0.1105, 0.0817, 0.0947]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.1573, -0.2670, -0.2161, -0.1595,  0.0249, -0.0397,  0.0568,  0.0696,\n",
      "         -0.1843, -0.3103],\n",
      "        [ 0.3402, -0.5860,  0.1103,  0.0939, -0.1159,  0.0831,  0.2598,  0.3279,\n",
      "         -0.3389, -0.2668]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.1262, 0.0825, 0.0869,  ..., 0.1156, 0.0897, 0.0790],\n",
      "        [0.1362, 0.0539, 0.1082,  ..., 0.1345, 0.0691, 0.0742],\n",
      "        [0.1036, 0.0863, 0.1167,  ..., 0.1204, 0.0808, 0.0939],\n",
      "        ...,\n",
      "        [0.1149, 0.0779, 0.1145,  ..., 0.1063, 0.0622, 0.0753],\n",
      "        [0.0933, 0.0748, 0.1129,  ..., 0.1260, 0.0671, 0.0723],\n",
      "        [0.0902, 0.1036, 0.1043,  ..., 0.1038, 0.0897, 0.0849]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[-0.1148,  0.0300,  0.0305,  0.0055,  0.1501,  0.0394, -0.0697,  0.0206,\n",
      "         -0.2324, -0.0115],\n",
      "        [ 0.3995,  0.0669,  0.0309, -0.1404, -0.1673, -0.2206,  0.1878,  0.0904,\n",
      "         -0.2005, -0.1392]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.0901, 0.1041, 0.1042,  ..., 0.1032, 0.0801, 0.0999],\n",
      "        [0.1477, 0.1059, 0.1021,  ..., 0.1084, 0.0810, 0.0862],\n",
      "        [0.1172, 0.0829, 0.0986,  ..., 0.1147, 0.0833, 0.0989],\n",
      "        ...,\n",
      "        [0.0937, 0.0476, 0.1097,  ..., 0.1362, 0.0649, 0.1000],\n",
      "        [0.1352, 0.0764, 0.0874,  ..., 0.1120, 0.0855, 0.0921],\n",
      "        [0.0786, 0.0538, 0.1147,  ..., 0.1464, 0.0852, 0.1140]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.2451, -0.3579,  0.0861, -0.0108, -0.0206, -0.1136,  0.3067,  0.4544,\n",
      "         -0.4860, -0.1763],\n",
      "        [-0.0224, -0.0651, -0.0943, -0.0175, -0.1426, -0.1259,  0.1814,  0.2159,\n",
      "         -0.2148, -0.1451]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.1239, 0.0678, 0.1057,  ..., 0.1527, 0.0596, 0.0813],\n",
      "        [0.1011, 0.0969, 0.0941,  ..., 0.1284, 0.0834, 0.0895],\n",
      "        [0.1173, 0.1040, 0.1004,  ..., 0.0898, 0.0768, 0.0883],\n",
      "        ...,\n",
      "        [0.1067, 0.0872, 0.0897,  ..., 0.1403, 0.0805, 0.0775],\n",
      "        [0.1158, 0.0967, 0.0886,  ..., 0.0931, 0.0908, 0.1017],\n",
      "        [0.1061, 0.1081, 0.0877,  ..., 0.0870, 0.0840, 0.1009]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[-0.1796, -0.5662,  0.6651,  0.0554,  0.0064, -0.0560, -0.0414,  0.5480,\n",
      "         -0.4478, -0.1142],\n",
      "        [ 0.2051,  0.0845, -0.0131,  0.2456, -0.1242,  0.0755,  0.2622,  0.1819,\n",
      "         -0.2285, -0.1079]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.0790, 0.0537, 0.1839,  ..., 0.1635, 0.0604, 0.0843],\n",
      "        [0.1144, 0.1014, 0.0919,  ..., 0.1117, 0.0741, 0.0836],\n",
      "        [0.1205, 0.0821, 0.0820,  ..., 0.1126, 0.0861, 0.0895],\n",
      "        ...,\n",
      "        [0.1043, 0.1061, 0.0975,  ..., 0.1290, 0.0779, 0.0861],\n",
      "        [0.1065, 0.1220, 0.0935,  ..., 0.1106, 0.0790, 0.0931],\n",
      "        [0.1098, 0.0982, 0.0781,  ..., 0.1041, 0.0887, 0.0910]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.0216, -0.1222, -0.1704,  0.0307, -0.0340,  0.0347,  0.0108,  0.0145,\n",
      "         -0.0980, -0.0773],\n",
      "        [ 0.2277, -0.4338, -0.1247, -0.2984,  0.0518,  0.1495,  0.2237,  0.2686,\n",
      "          0.1673,  0.0797]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.1060, 0.0918, 0.0875,  ..., 0.1052, 0.0940, 0.0960],\n",
      "        [0.1188, 0.0613, 0.0835,  ..., 0.1238, 0.1119, 0.1025],\n",
      "        [0.0984, 0.0713, 0.0911,  ..., 0.1273, 0.0910, 0.0968],\n",
      "        ...,\n",
      "        [0.1034, 0.0428, 0.1004,  ..., 0.1913, 0.0726, 0.0978],\n",
      "        [0.1147, 0.0898, 0.1091,  ..., 0.0954, 0.0739, 0.0902],\n",
      "        [0.1348, 0.0898, 0.0907,  ..., 0.1358, 0.0721, 0.0853]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[-0.0245, -0.1779,  0.0426, -0.2147, -0.0822, -0.2309,  0.4833,  0.3159,\n",
      "         -0.3336, -0.3088],\n",
      "        [ 0.2556, -0.2691,  0.0433, -0.1303,  0.0216,  0.3210,  0.3465,  0.5236,\n",
      "          0.1474,  0.2615]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.0994, 0.0852, 0.1062,  ..., 0.1396, 0.0729, 0.0748],\n",
      "        [0.1082, 0.0640, 0.0875,  ..., 0.1414, 0.0971, 0.1088],\n",
      "        [0.0977, 0.0649, 0.0992,  ..., 0.1057, 0.0864, 0.0847],\n",
      "        ...,\n",
      "        [0.0986, 0.0812, 0.0913,  ..., 0.1259, 0.1042, 0.0933],\n",
      "        [0.1266, 0.0763, 0.0881,  ..., 0.1478, 0.0695, 0.0906],\n",
      "        [0.1075, 0.0860, 0.0860,  ..., 0.1089, 0.0887, 0.0872]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.1475, -0.0165,  0.1521,  0.1505,  0.0130,  0.2509,  0.2460,  0.3429,\n",
      "         -0.2787, -0.2733],\n",
      "        [ 0.4504, -0.2958, -0.1237,  0.0760, -0.1478, -0.0507,  0.2150,  0.1480,\n",
      "         -0.3007, -0.1256]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.1056, 0.0896, 0.1061,  ..., 0.1284, 0.0690, 0.0693],\n",
      "        [0.1552, 0.0736, 0.0874,  ..., 0.1147, 0.0732, 0.0872],\n",
      "        [0.1070, 0.0780, 0.0863,  ..., 0.1139, 0.0814, 0.0866],\n",
      "        ...,\n",
      "        [0.1163, 0.0718, 0.0975,  ..., 0.1299, 0.0728, 0.0843],\n",
      "        [0.1106, 0.0702, 0.1255,  ..., 0.0841, 0.0677, 0.0686],\n",
      "        [0.1022, 0.0612, 0.1103,  ..., 0.1448, 0.0699, 0.0795]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n",
      "tensor([[ 0.1749, -0.0311, -0.0034,  0.0181,  0.1013, -0.2515,  0.0913,  0.1236,\n",
      "         -0.2338, -0.1912],\n",
      "        [ 0.0776,  0.0482,  0.0524,  0.0726,  0.0164,  0.0147, -0.1113,  0.0723,\n",
      "         -0.3540,  0.0108]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.1203, 0.0979, 0.1006,  ..., 0.1142, 0.0799, 0.0834],\n",
      "        [0.1084, 0.1052, 0.1057,  ..., 0.1078, 0.0704, 0.1014],\n",
      "        [0.1272, 0.0824, 0.0791,  ..., 0.1029, 0.0881, 0.0865],\n",
      "        ...,\n",
      "        [0.1381, 0.0892, 0.0796,  ..., 0.1147, 0.0852, 0.0933],\n",
      "        [0.0932, 0.0850, 0.1036,  ..., 0.1265, 0.0853, 0.0849],\n",
      "        [0.1023, 0.0645, 0.0810,  ..., 0.1405, 0.0803, 0.0862]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([500, 10])\n"
     ]
    }
   ],
   "source": [
    "for image, label in train_data:\n",
    "    output = model(image)\n",
    "    print(output[:2])\n",
    "    real_output = F.softmax(output, dim = 1)\n",
    "    print(real_output)\n",
    "    print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_output = F.softmax(output, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.1203, 0.0979, 0.1006,  ..., 0.1142, 0.0799, 0.0834],\n",
       "        [0.1084, 0.1052, 0.1057,  ..., 0.1078, 0.0704, 0.1014],\n",
       "        [0.1272, 0.0824, 0.0791,  ..., 0.1029, 0.0881, 0.0865],\n",
       "        ...,\n",
       "        [0.1381, 0.0892, 0.0796,  ..., 0.1147, 0.0852, 0.0933],\n",
       "        [0.0932, 0.0850, 0.1036,  ..., 0.1265, 0.0853, 0.0849],\n",
       "        [0.1023, 0.0645, 0.0810,  ..., 0.1405, 0.0803, 0.0862]],\n",
       "       grad_fn=<SoftmaxBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "real_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.sum(real_output[:5]).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([0, 0, 0, 6, 0, 0, 7, 6, 6, 6, 0, 0, 7, 6, 2, 6, 6, 0, 7, 6, 3, 7, 0, 7,\n",
      "        6, 7, 6, 6, 6, 0, 6, 6, 7, 5, 7, 6, 0, 7, 4, 6, 0, 7, 7, 4, 5, 7, 7, 7,\n",
      "        6, 2])\n",
      "REAL LABELS\n",
      "tensor([9, 1, 5, 5, 7, 6, 4, 9, 4, 2, 8, 4, 8, 2, 1, 3, 6, 3, 7, 2, 3, 0, 8, 8,\n",
      "        2, 9, 8, 1, 3, 6, 6, 2, 8, 6, 7, 9, 2, 9, 9, 6, 7, 7, 8, 4, 6, 3, 0, 6,\n",
      "        6, 9])\n"
     ]
    }
   ],
   "source": [
    "best_prob, pred = torch.max(real_output, dim = 1)\n",
    "# print(best_prob)\n",
    "print(pred[:50])\n",
    "print(\"REAL LABELS\")\n",
    "print(label[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.124"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "#creating evaluation metric and loss function\n",
    "def accuracy(predicted, actual_label):\n",
    "    return torch.sum(predicted == actual_label).item() / len(predicted)\n",
    "\n",
    "accuracy(pred, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loss_fn(pred, label):\n",
    "    loss_fn  = F.cross_entropy\n",
    "    loss = loss_fn(pred, label)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.SGD(model.parameters(), lr = 0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def train_loss(model, loss_fn,  train_dl, optimizer = None, metric = None):\n",
    "    for image, label in train_dl:\n",
    "        pred = model(image)\n",
    "        loss = loss_fn(pred, label)\n",
    "        # real_output = F.softmax(pred)\n",
    "        best_prob, pred = torch.max(pred, dim = 1)\n",
    "        \n",
    "        if optimizer is not None:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        metric_result = None\n",
    "        if metric is not None:\n",
    "            metric_result = metric(pred, label)\n",
    "\n",
    "        return loss.item(), len(image), metric_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2.297713041305542, 500, 0.13)"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "train_loss(model, loss_fn,  train_data, optimizer = optim, metric = accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_loss(model, loss_fn, val_dl, metric = None):\n",
    "    losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, label in val_dl:\n",
    "            pred = model(image)\n",
    "            loss = loss_fn(pred, label)\n",
    "            losses.append(loss)\n",
    "            # real_output = F.softmax(pred)\n",
    "            best_prob, pred = torch.max(real_output, dim = 1)\n",
    "\n",
    "            # final_loss = sum(losses).item()/len(image))\n",
    "\n",
    "            metric_result = None\n",
    "            if metric is not None:\n",
    "                metric_result = metric(pred, label)\n",
    "\n",
    "            return  loss.item(), len(image), metric_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2.3038790225982666, 500, 0.09)"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "val_loss(model, loss_fn, val_data, metric = accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, model, loss_fn,  train_dl, val_dl, optimizer = None, metric = None):\n",
    "    for epoch in range(epochs):\n",
    "        train_loss(model, loss_fn,  train_dl, optimizer = None, metric = accuracy)\n",
    "\n",
    "        loss, total_len, metric_result = val_loss(model, loss_fn, val_dl, metric  = accuracy)\n",
    "\n",
    "        print('{}/{}, {}, {}'.format(epoch +1 , epochs, loss, metric_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1/5, 2.2939298152923584, 0.096\n",
      "2/5, 2.2914860248565674, 0.088\n",
      "3/5, 2.297717332839966, 0.086\n",
      "4/5, 2.2920732498168945, 0.082\n",
      "5/5, 2.296963691711426, 0.1\n"
     ]
    }
   ],
   "source": [
    "fit(5, model, loss_fn,  train_data, val_data, optimizer = optim, metric = accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feedforward network\n",
    "class MNIST_Feedforward(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net1 = nn.Linear(784, 128)\n",
    "        self.net2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, image):\n",
    "        image = image.view(image.size(0), -1)\n",
    "        # image = image.reshape(-1, 28*28)\n",
    "        image = F.relu(self.net1(image))\n",
    "        image = F.relu(self.net2(image))\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNIST_Feedforward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.302446126937866\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_data:\n",
    "    pred = model(x)\n",
    "    loss = loss_fn(pred, label)\n",
    "    print(loss.item())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([128, 784])\n",
      "torch.Size([128])\n",
      "torch.Size([10, 128])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for parameter in model.parameters():\n",
    "    print(parameter.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "source": [
    "# GPU\n",
    "torch.cuda.is_available()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "interpreter": {
   "hash": "9d3bae0a0f66551680ef8a166f6b92cc2774d5d7901f027deb7bb883ed06d5ae"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}